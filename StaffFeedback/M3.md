# SwEnt M3 Team Grading Report

This M3 milestone is the culmination of your SwEnt journey, and it gives us the final opportunity to give you, as a team, formal feedback on how you performed in the project. By now, you should be capable of demonstrating a solid command of the Scrum methodology and collaborative teamwork, and be able to deliver a high-quality application that is ready for real users.
This feedback report is meant to complement the informal, ungraded feedback that you received from your coaches during the weekly meetings, over email, on Discord, etc.

You can find the evaluation criteria in the [M3 Deliverables](https://github.com/swent-epfl/public/blob/main/project/M3.md) document.
As mentioned before, the standards for M2 were elevated relative to M1, and this progression continued into M3: we now hold you to the highest professional standard in SwEnt.

---

## Blue Belt

You qualified for a Blue Belt ü•ãüîµ and got a final team grade of 5.03/6 for M3. Excellent work! You're demonstrating advanced skills.

We looked at several aspects, grouped into seven categories for the team grade. Here is the breakdown of the points you earned:

| Metric                                   | **Points Earned**                | **Weight** | **Feedback**                               |
|------------------------------------------|----------------------------------|------------|--------------------------------------------|
| **Completeness**                         | 5.1 out of 6 | 20%        | [See Details](#completeness)               |
| **Functionality**                        | 4.8 out of 6 | 20%       | [See Details](#functionality)              |
| **User Experience**                      | 3.4 out of 6 | 5%       | [See Details](#user-experience)            |
| **Design and Maintainability**           | 5.55 out of 6 | 20% | [See Details](#design-and-maintainability) |
| **QA (Testing)**                         | 5.03 out of 6           | 20%        | [See Details](#qa-testing)                 |
| **Documentation**                        | 4.75 out of 6 | 10%       | [See Details](#documentation)              |
| **Autonomy**                             | 5.7 out of 6     | 5%         | [See Details](#autonomy)                   |
| **Final Team Grade**                     | **5.03 out of 6** |            |                                            |

In addition to the feedback you received from the coaches during the Sprints, you will find more detailed comments below.

---

## Completeness

We first evaluated the depth and complexity of the main epics in your app, along with their contribution to the app, the tangible value they provide to the user, and their alignment with the app‚Äôs goals.

We evaluated the extent to which your app meets the course requirements articulated at the start of the semester, and whether they are implemented effectively, they integrate seamlessly, and are indeed essential to the app.

We also looked at the robustness and completeness of the different features you implemented: are all the features finished and polished, are they secure and bug-free, and are they thoughtfully designed.

The app covers the required functional areas well and demonstrates a solid overall concept. It integrates a public cloud service meaningfully, uses authentication appropriately, and incorporates a phone sensor in a way that adds value to the application. Support for offline usage is implemented and allows users to access key content without an active internet connection.

While the main features are present, some feel slightly incomplete from a user-facing perspective. Certain expected refinements and finishing touches are missing, which affects the perceived level of polish. 

For this part, you received 5.1/6.

---

## Functionality

In this context, we assessed your app's ability to handle unexpected inputs provided by clueless or malicious users (including spamming buttons, entering wrong inputs, stopping a process mid-way, etc.); we wanted to see that your app handles all edge cases gracefully, has comprehensive error handling, and includes robust mechanisms for maintaining stability under stress.

We then evaluated the performance and reliability of the final product, i.e., the APK: we wanted to see that your APK is stable and the UI responds quickly and has seamless navigation.

Next we looked into your implementation of user authentication and multi-user support: does the app correctly manage users, can users personalize their accounts, does the app support session persistence, are multi-user interactions well supported, can accounts be used on another device, and is account information preserved when switching devices.

The app‚Äôs core flows are generally usable, but their reliability is significantly affected by issues around location handling. In particular, location selection is inconsistent and can fail after multiple attempts, which blocks event creation entirely. This behavior represents a major robustness issue, as users can become stuck without a clear way to recover.

Data persistence and consistency work well overall. Stored data remains stable across sessions, and no major synchronization or data loss problems were observed.

Robustness against invalid or unexpected input could be improved. Several inputs are insufficiently validated, most notably the Country/Region field, which accepts arbitrary values. Together with the unstable location selection, this indicates missing safeguards against common user errors.
The filter does not work on series (or vents inside the series), it only works on the direct events. 

All functional checklist requirements are met: account creation, login, re-login, and the main collaborative functionality work as intended.

Overall, while the technical foundation is solid, unreliable location handling and weak input validation noticeably reduce the app‚Äôs robustnes.

For this part, you received 4.8/6.

---

## User Experience

For this part, we wanted to see how intuitive and user-friendly the app is for real users. Beyond having good usability, did you pay attention to streamlining the interactions, is it easy to figure out, can new users start making good use of the app quickly, are the interaction flows well thought out and refined.

Some layout elements use fixed sizes that do not adapt well across screen sizes. Introducing more responsive sizing would improve usability and perceived polish.

For first-time users, the app is difficult to understand and lacks a clear starting point. The initial overview screen is empty (‚Äúyou have no events yet‚Äù) and does not explain the purpose of the app, what kind of content users should expect, or what the recommended next step is. While actions such as viewing history, adding an event, or adding a series are available, they are presented without guidance, making the first interaction feel unstructured and confusing. As a result, users must rely on trials and errors to understand when and why to use each view.

On the profile screen specifically, several top actions are available (view profile, edit profile, and groups), but their purpose and relationship are unclear. In particular, the groups entry point feels disconnected from the rest of the profile context. It is not obvious why group management is accessed from the profile, what role groups play in the overall app experience, or how they relate to events, chats, and social interactions.

The social model is also difficult to understand. Although the app shows followers and following, users can only follow people from within their groups. There is no way to follow users from shared events, event chats, or discovery views, which creates a mismatch between what the interface suggests and what the app actually supports.

Overall, the main challenge is not the number of features, but the lack of explanation and coherence between them. Clearer onboarding, and a more explicit explanation of how events, groups, discovery, and social interactions fit together would significantly improve usability and make the app feel more approachable and intentional, especially for new users.

For this part, you received 3.4/6.

---

## Design and Maintainability

We evaluated whether your code is of high quality and employs best practices.
We expect the codebase to be polished, well documented, follow consistent conventions, be modular, and allow for easy modifications.
You should be able to employ advanced techniques by now, such as asynchronous functions (flows, coroutines), good resource management, and automated dependency injection (e.g., with Hilt).

We also assessed your overall app architecture and design, looking in particular at aspects surrounding robustness and scalability.
We looked at both the codebase and the documentation of the app (Wiki and architecture diagram), we expect your design to demonstrate thoughtful consideration for performance, maintainability, and future growth.

The architecture is pretty solid and should be scalable.

The repository is well orgamised and the code is clean and readable.

For this part, you received 5.55/6.

---

## QA (Testing)

The first aspect we looked at here was your test suite, in terms of both quality and the final line coverage.
We expect the testing to be rigorous and to cover all components and edge cases, and they should validate every significant user journey.
Your end-to-end tests should be detailed and include error-handling scenarios.
The tests should be well-documented and easy to maintain.
Finally, your test suite should demonstrate advanced techniques, mock data for performance testing, and automated regression tests.

Sonar is integrated into the repository, providing visibility into code quality issues and helping maintain a high standard of reliability. 

The end-to-end tests are not implemented the way they are exepected, you should have one test for a fulll user flow, and not several subtests.

For this part, you received 5.03/6.

---

## Documentation

We looked at your README and GitHub Wiki to evaluate the quality and completeness of your app‚Äôs documentation. We expect the README and Wiki to be thorough and achieve professional-level clarity and completeness.
They should provide detailed descriptions of the app's architecture, implementation of the features, the development setup and guidelines for contributing.

We also assessed your use of Figma and the architecture diagram for effective UI design, organization, and app structure planning.
By this stage, we expect your Figma and Architecture diagram to be complete and up-to-date. The Figma should be consistent with the UI and the Architecture diagram should be comprehensive.

The Architecture diagram is pretty complete but could have benefited from being a bit clearer (the arrows are kind of messy which makes it confusing).

The Figma is pretty complete but could have been improved further by having a more complete working prototype that would show how the application should work.

The readme and the wiki contains useful documentation and the base code is overall pretty well documented.

No additional developer-oriented documentation is provided. Supplementary materials such as CONTRIBUTING guidelines, module documentation, or API usage notes would help improve maintainability and ease onboarding for future contributors.

For this part, you received 4.75/6.

---

## Autonomy

A primary goal of SwEnt is to teach you how to function autonomously as a team.
For this part of the evaluation, we assessed you team‚Äôs independence, spanning Sprint 6 to Sprint 10, based on the meetings with coaches, Sprint planning, and how you managed risk.
By this stage, coaches should no longer be necessary for the team to operate, i.e., you can organize yourselves, you don't need to be reminded about tasks, and you can conduct the Scrum ceremonies on your own.

The team demonstrated autonomy during meetings, structuring discussions effectively and following the Scrum ceremony process without needing significant coach intervention. Sometimes the order in which the Scrum ceremony should be done was a bit off, but all the elements were always mentionned.

The team maintained a respectful, constructive, and professional tone in meetings and discussions, contributing positively to collaboration and team cohesion.

For this part, you received 5.7/6.

---

## Summary

Based on the above points, your grade for this M3 milestone is 5.03/6. If you are interested in how this fits into the bigger grading scheme, please see [project README](https://github.com/swent-epfl/public/blob/main/project/README.md) and the [course README](https://github.com/swent-epfl/public/blob/main/README.md).

The entire SwEnt staff wishes you the very best in your career, and we look forward to seeing you do great things with what you learned this semester.



